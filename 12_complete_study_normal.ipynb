{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8baca321-dce7-4907-b555-420f41bd25b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f6f9024-fe7a-4a2a-842f-935b6a6b7822",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-02 06:30:07.676587: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-02 06:30:07.676619: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-02 06:30:07.677688: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-02 06:30:07.684292: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-02 06:30:08.516893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from new_aeb_gplvm import *\n",
    "from utils.data_generator import DataGenerator\n",
    "from utils.myutils import Utils\n",
    "from tqdm import trange\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm_notebook\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "utils = Utils()\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6f6842a-7788-45cd-8a6e-0b84ef7cd505",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataframe(experiment):\n",
    "    datagenerator = DataGenerator()\n",
    "\n",
    "    noise_type = (\n",
    "        None if experiment[\"noise_type\"] == \"normal\" else experiment[\"noise_type\"]\n",
    "    )  # irrelevant,duplicated\n",
    "    anomaly_type = (\n",
    "        None if experiment[\"anomaly_type\"] == \"normal\" else experiment[\"anomaly_type\"]\n",
    "    )  # cluster,global,local,dependency\n",
    "\n",
    "    datagenerator.dataset = experiment[\"dataset\"]\n",
    "    data = datagenerator.generator(\n",
    "        la=1.00,\n",
    "        realistic_synthetic_mode=anomaly_type,\n",
    "        noise_type=noise_type,\n",
    "        noise_ratio=float(experiment[\"noise_ratio\"]),\n",
    "        stdscale=True,\n",
    "        minmax=False,\n",
    "    )\n",
    "\n",
    "    Y_train = torch.tensor(data[\"X_train\"], dtype=torch.float32)\n",
    "    Y_test = torch.tensor(data[\"X_test\"], dtype=torch.float32)\n",
    "    lb_train = torch.tensor(data[\"y_train\"], dtype=torch.float32)\n",
    "    lb_test = torch.tensor(data[\"y_test\"], dtype=torch.float32)\n",
    "\n",
    "    return Y_train, Y_test, lb_train, lb_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd004deb-5503-456c-b961-009ed1657783",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXPERIMENTS_FILE = \"experiments/complete/000_datasets_01_47_normal.json\"\n",
    "with open(EXPERIMENTS_FILE) as file:\n",
    "    experiments = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8ab971c-9da5-4a1f-9617-e830c8ae5dcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (\n",
    "#    df.replace({\"anomaly_type\": \"normal\"}, \"cluster\").to_json(\n",
    "#        \"experiments/complete/001_datasets_01_to_06_cluster.json\", orient=\"records\"\n",
    "#    )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fb576e-7dd3-4065-8e0b-a14d570d6414",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16521/1405413897.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for experiment in tqdm_notebook(experiments):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "517e9e646ca643898de261f2f23725f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3384 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsampling for dataset 01_ALOI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/OE-GPLVM/new_aeb_gplvm.py:319: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1686274778240/work/aten/src/ATen/native/TensorShape.cpp:3571.)\n",
      "  klu_expanded = ll_shape.T.add_(klu).sum(-1).T.div((self.n_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsampling for dataset 01_ALOI...\n",
      "subsampling for dataset 01_ALOI...\n",
      "subsampling for dataset 01_ALOI...\n",
      "subsampling for dataset 32_shuttle...\n",
      "subsampling for dataset 32_shuttle...\n",
      "subsampling for dataset 32_shuttle...\n",
      "subsampling for dataset 32_shuttle...\n"
     ]
    }
   ],
   "source": [
    "success_experiments = []\n",
    "failed_experiments = []\n",
    "for experiment in tqdm_notebook(experiments):\n",
    "    Y_train, Y_test, lb_train, lb_test = create_dataframe(experiment)\n",
    "    Y_val, Y_test, lb_val, lb_test = train_test_split(\n",
    "        Y_test, lb_test, test_size=0.50, random_state=42\n",
    "    )\n",
    "\n",
    "    if experiment[\"loss\"] == \"normal\":\n",
    "        idx_n = np.where(lb_train == 0)[0]\n",
    "        Y_train_normal = Y_train[idx_n]\n",
    "        lb_train_normal = lb_train[idx_n]\n",
    "\n",
    "    n_train = len(Y_train_normal)\n",
    "    data_dim = Y_train_normal.shape[1]\n",
    "    kernel = experiment[\"kernel\"]\n",
    "    latent_dim = int(experiment[\"latent_dim\"])\n",
    "    nn_layers = tuple(map(int, experiment[\"layers\"].split(\",\")))\n",
    "    n_inducing = int(experiment[\"n_inducing\"])\n",
    "    n_epochs = int(experiment[\"n_epochs\"])\n",
    "    lr = float(experiment[\"learning_rate\"])\n",
    "    batch_size = int(experiment[\"batch_size\"])\n",
    "\n",
    "    # print(experiment)\n",
    "\n",
    "    try:\n",
    "        gplvm = AD_GPLVM(\n",
    "            latent_dim, n_inducing, n_epochs, nn_layers, lr, batch_size, kernel\n",
    "        )\n",
    "\n",
    "        # Fitting the Model\n",
    "        train_start_time = time.time()\n",
    "        gplvm.fit(Y_train_normal)\n",
    "        train_end_time = time.time()\n",
    "\n",
    "        # Validating the Model\n",
    "        val = []\n",
    "        for i in range(100):\n",
    "            score = gplvm.predict_score(Y_val)\n",
    "            val.append(score)\n",
    "        validation_score = np.mean(val, axis=0)\n",
    "        # validation_score = gplvm.calculate_train_elbo(Y_train_normal)\n",
    "\n",
    "        # Results\n",
    "        pred_start_time = time.time()\n",
    "        test_score = gplvm.predict_score(Y_test)\n",
    "        pred_end_time = time.time()\n",
    "\n",
    "        # Save Metrics\n",
    "        metrics = utils.metric(y_true=lb_val, y_score=validation_score)\n",
    "        validation_metrics = utils.metric(y_true=lb_test, y_score=test_score)\n",
    "        experiment[\"negative_elbo\"] = validation_score.sum()  # validation_score.sum()\n",
    "        experiment[\"train_loss_curve\"] = gplvm.loss_list\n",
    "        experiment[\"val_auc_roc\"] = validation_metrics[\"aucroc\"]\n",
    "        experiment[\"val_auc_pr\"] = validation_metrics[\"aucpr\"]\n",
    "        experiment[\"test_auc_roc\"] = metrics[\"aucroc\"]\n",
    "        experiment[\"test_auc_pr\"] = metrics[\"aucpr\"]\n",
    "        experiment[\"training_time\"] = train_end_time - train_start_time\n",
    "        experiment[\"inference_time\"] = pred_end_time - pred_start_time\n",
    "\n",
    "        # Reconstrucao\n",
    "        Y_val_recon, Y_val_recon_covar = gplvm.model.reconstruct_y(Y_val)\n",
    "        experiment[\"val_reconstruct_error\"] = float(utils.rmse(Y_val, Y_val_recon.T))\n",
    "\n",
    "        utils.save_experiment(experiment)\n",
    "\n",
    "    except Exception as error:\n",
    "        print(\"An exception occurred:\", error)\n",
    "        experiment[\"test_auc_roc\"] = 0.0\n",
    "        experiment[\"test_auc_pr\"] = 0.0\n",
    "        utils.save_experiment(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fe5f9f-2ea4-47dc-8aee-73b3cd3dfa06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(success_experiments).to_json(\"experiments/kernels/001_matern_rbf_all_results.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec70278-e442-416f-860d-56ddc979f8d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# success_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45590c1d-4f4b-4af7-9ebd-6e5067d65da3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_multi = pd.DataFrame(success_experiments)\n",
    "df_multi.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847d4825-fdeb-4a4d-af1c-d689a5654048",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_multi.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57467c55-e1dc-4014-8df7-5c5df351e1a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x, y = \"test_auc_roc\", \"val_auc_pr\"\n",
    "filter_df = df_multi.dataset == \"29_Pima\"\n",
    "plt.scatter(df_multi[filter_df][x], df_multi[filter_df][y])\n",
    "plt.xlabel(x)\n",
    "plt.ylabel(y)\n",
    "plt.title(pearsonr(df_multi[filter_df][x], df_multi[filter_df][y]).statistic)\n",
    "None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
