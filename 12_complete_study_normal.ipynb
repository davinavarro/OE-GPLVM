{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baca321-dce7-4907-b555-420f41bd25b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f9024-fe7a-4a2a-842f-935b6a6b7822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from new_aeb_gplvm import *\n",
    "from utils.data_generator import DataGenerator\n",
    "from utils.myutils import Utils\n",
    "from tqdm import trange\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm_notebook\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "utils = Utils()\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f6842a-7788-45cd-8a6e-0b84ef7cd505",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataframe(experiment):\n",
    "    datagenerator = DataGenerator()\n",
    "\n",
    "    noise_type = (\n",
    "        None if experiment[\"noise_type\"] == \"normal\" else experiment[\"noise_type\"]\n",
    "    )  # irrelevant,duplicated\n",
    "    anomaly_type = (\n",
    "        None if experiment[\"anomaly_type\"] == \"normal\" else experiment[\"anomaly_type\"]\n",
    "    )  # cluster,global,local,dependency\n",
    "\n",
    "    datagenerator.dataset = experiment[\"dataset\"]\n",
    "    data = datagenerator.generator(\n",
    "        la=1.00,\n",
    "        realistic_synthetic_mode=anomaly_type,\n",
    "        noise_type=noise_type,\n",
    "        noise_ratio=float(experiment[\"noise_ratio\"]),\n",
    "        stdscale=True,\n",
    "        minmax=False,\n",
    "    )\n",
    "\n",
    "    Y_train = torch.tensor(data[\"X_train\"], dtype=torch.float32)\n",
    "    Y_test = torch.tensor(data[\"X_test\"], dtype=torch.float32)\n",
    "    lb_train = torch.tensor(data[\"y_train\"], dtype=torch.float32)\n",
    "    lb_test = torch.tensor(data[\"y_test\"], dtype=torch.float32)\n",
    "\n",
    "    return Y_train, Y_test, lb_train, lb_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd004deb-5503-456c-b961-009ed1657783",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXPERIMENTS_FILE = \"experiments/complete/001_datasets_01_to_06_all.json\"\n",
    "with open(EXPERIMENTS_FILE) as file:\n",
    "    experiments = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8e938e-1d9a-4fc1-b5a7-515deabee2a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (\n",
    "#    df.replace({\"anomaly_type\": \"normal\"}, \"cluster\").to_json(\n",
    "#        \"experiments/complete/001_datasets_01_to_06_cluster.json\", orient=\"records\"\n",
    "#    )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fb576e-7dd3-4065-8e0b-a14d570d6414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "success_experiments = []\n",
    "failed_experiments = []\n",
    "for experiment in tqdm_notebook(experiments[:10]):\n",
    "    Y_train, Y_test, lb_train, lb_test = create_dataframe(experiment)\n",
    "    Y_val, Y_test, lb_val, lb_test = train_test_split(\n",
    "        Y_test, lb_test, test_size=0.50, random_state=42\n",
    "    )\n",
    "\n",
    "    if experiment[\"loss\"] == \"normal\":\n",
    "        idx_n = np.where(lb_train == 0)[0]\n",
    "        Y_train_normal = Y_train[idx_n]\n",
    "        lb_train_normal = lb_train[idx_n]\n",
    "\n",
    "    n_train = len(Y_train_normal)\n",
    "    data_dim = Y_train_normal.shape[1]\n",
    "    kernel = experiment[\"kernel\"]\n",
    "    latent_dim = int(experiment[\"latent_dim\"])\n",
    "    nn_layers = tuple(map(int, experiment[\"layers\"].split(\",\")))\n",
    "    n_inducing = int(experiment[\"n_inducing\"])\n",
    "    n_epochs = int(experiment[\"n_epochs\"])\n",
    "    lr = float(experiment[\"learning_rate\"])\n",
    "    batch_size = int(experiment[\"batch_size\"])\n",
    "\n",
    "    # print(experiment)\n",
    "\n",
    "    try:\n",
    "        gplvm = AD_GPLVM(\n",
    "            latent_dim, n_inducing, n_epochs, nn_layers, lr, batch_size, kernel\n",
    "        )\n",
    "\n",
    "        # Fitting the Model\n",
    "        train_start_time = time.time()\n",
    "        gplvm.fit(Y_train_normal)\n",
    "        train_end_time = time.time()\n",
    "\n",
    "        # Validating the Model\n",
    "        val = []\n",
    "        for i in range(100):\n",
    "            score = gplvm.predict_score(Y_val)\n",
    "            val.append(score)\n",
    "        validation_score = np.mean(val, axis=0)\n",
    "        # validation_score = gplvm.calculate_train_elbo(Y_train_normal)\n",
    "\n",
    "        # Results\n",
    "        pred_start_time = time.time()\n",
    "        test_score = gplvm.predict_score(Y_test)\n",
    "        pred_end_time = time.time()\n",
    "\n",
    "        # Save Metrics\n",
    "        metrics = utils.metric(y_true=lb_val, y_score=validation_score)\n",
    "        validation_metrics = utils.metric(y_true=lb_test, y_score=test_score)\n",
    "        experiment[\"negative_elbo\"] = validation_score.sum()  # validation_score.sum()\n",
    "        experiment[\"train_loss_curve\"] = gplvm.loss_list\n",
    "        experiment[\"val_auc_roc\"] = validation_metrics[\"aucroc\"]\n",
    "        experiment[\"val_auc_pr\"] = validation_metrics[\"aucpr\"]\n",
    "        experiment[\"test_auc_roc\"] = metrics[\"aucroc\"]\n",
    "        experiment[\"test_auc_pr\"] = metrics[\"aucpr\"]\n",
    "        experiment[\"training_time\"] = train_end_time - train_start_time\n",
    "        experiment[\"inference_time\"] = pred_end_time - pred_start_time\n",
    "\n",
    "        # Reconstrucao\n",
    "        Y_val_recon, Y_val_recon_covar = gplvm.model.reconstruct_y(Y_val)\n",
    "        experiment[\"val_reconstruct_error\"] = float(utils.rmse(Y_val, Y_val_recon.T))\n",
    "\n",
    "        utils.save_experiment(experiment)\n",
    "\n",
    "    except Exception as error:\n",
    "        print(\"An exception occurred:\", error)\n",
    "        experiment[\"test_auc_roc\"] = 0.0\n",
    "        experiment[\"test_auc_pr\"] = 0.0\n",
    "        utils.save_experiment(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fe5f9f-2ea4-47dc-8aee-73b3cd3dfa06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(success_experiments).to_json(\"experiments/kernels/001_matern_rbf_all_results.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec70278-e442-416f-860d-56ddc979f8d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# success_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45590c1d-4f4b-4af7-9ebd-6e5067d65da3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_multi = pd.DataFrame(success_experiments)\n",
    "df_multi.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847d4825-fdeb-4a4d-af1c-d689a5654048",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_multi.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57467c55-e1dc-4014-8df7-5c5df351e1a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x, y = \"test_auc_roc\", \"val_auc_pr\"\n",
    "filter_df = df_multi.dataset == \"29_Pima\"\n",
    "plt.scatter(df_multi[filter_df][x], df_multi[filter_df][y])\n",
    "plt.xlabel(x)\n",
    "plt.ylabel(y)\n",
    "plt.title(pearsonr(df_multi[filter_df][x], df_multi[filter_df][y]).statistic)\n",
    "None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
