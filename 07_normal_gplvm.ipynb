{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4110f34-3e7e-4b49-a60f-5f958dce88e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 01:35:47.406805: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-29 01:35:47.455030: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from new_aeb_gplvm import *\n",
    "from utils.data_generator import DataGenerator\n",
    "from utils.myutils import Utils\n",
    "from tqdm import trange\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm_notebook\n",
    "random.seed(42)\n",
    "import json\n",
    "import os\n",
    "datagenerator = DataGenerator()\n",
    "utils = Utils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f322eb9-88c4-44fb-99db-9a15cc45cbd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXPERIMENTS_FILE = \"experiments/normal/004_latent_inducing_experiments.json\"\n",
    "with open(EXPERIMENTS_FILE) as file:\n",
    "    experiments = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8371e40d-e997-4705-9f19-1201b71f37ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataframe(dataset):\n",
    "    datagenerator.dataset = dataset\n",
    "    data = datagenerator.generator(\n",
    "        la=1.00,\n",
    "        realistic_synthetic_mode=None,\n",
    "        stdscale=True,\n",
    "        minmax=False,\n",
    "        noise_type=None,\n",
    "    )\n",
    "    Y_train = torch.tensor(data[\"X_train\"], dtype=torch.float32)\n",
    "    Y_test = torch.tensor(data[\"X_test\"], dtype=torch.float32)\n",
    "    lb_train = torch.tensor(data[\"y_train\"], dtype=torch.float32)\n",
    "    lb_test = torch.tensor(data[\"y_test\"], dtype=torch.float32)\n",
    "    #idx_n = np.where(lb_train == 0)[0]\n",
    "    #Y_train = Y_train[idx_n]\n",
    "    #lb_train = lb_train[idx_n]\n",
    "    return Y_train, Y_test, lb_train, lb_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62411307-54e5-472f-8561-e6ea8aa1a6c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': '01_ALOI',\n",
       " 'kernel': 'rbf',\n",
       " 'layers': '5,5',\n",
       " 'latent_dim': 2,\n",
       " 'lr': 0.01,\n",
       " 'batch_size': 128,\n",
       " 'n_inducing': 50,\n",
       " 'n_epochs': 1000}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f81bd92-0989-42e1-8c95-cc98fab7a5cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for experiment in tqdm_notebook(experiments):\n",
    "    if \"auc_roc\" not in experiment.keys():\n",
    "        Y_train, Y_test, lb_train, lb_test = create_dataframe(experiment[\"dataset\"])\n",
    "        n_train = len(Y_train)\n",
    "        data_dim = Y_train.shape[1]\n",
    "        latent_dim = experiment[\"latent_dim\"]\n",
    "        nn_layers = tuple(map(int, experiment[\"layers\"].split(\",\")))\n",
    "        kernel = experiment[\"kernel\"]\n",
    "        n_inducing = experiment[\"n_inducing\"]\n",
    "\n",
    "        n_epochs = 1000\n",
    "        lr = 0.01\n",
    "        batch_size = 128\n",
    "\n",
    "        try:\n",
    "            gplvm = AD_GPLVM(\n",
    "                latent_dim, n_inducing, n_epochs, nn_layers, lr, batch_size\n",
    "            )\n",
    "            gplvm.fit(Y_train)\n",
    "            score = gplvm.predict_score(Y_test)\n",
    "            metrics = utils.metric(y_true=lb_test, y_score=score)\n",
    "\n",
    "            experiment[\"auc_roc\"] = metrics[\"aucroc\"]\n",
    "            experiment[\"auc_pr\"] = metrics[\"aucpr\"]\n",
    "        except:\n",
    "            experiment[\"auc_roc\"] = 0.00\n",
    "            experiment[\"auc_pr\"] = 0.00\n",
    "\n",
    "        experiment[\"lr\"] = lr\n",
    "        experiment[\"batch_size\"] = batch_size\n",
    "        experiment[\"n_inducing\"] = n_inducing\n",
    "        experiment[\"n_epochs\"] = n_epochs\n",
    "        # experiment[\"train_noise\"] =  float(lb_train.sum()/len(Y_train))\n",
    "\n",
    "        with open(\"experiments/normal/004_latent_inducing_results.json\", \"w\") as file:\n",
    "            json.dump(experiments, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eab75d5-9e28-4d8e-bc11-25a4d26ff095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
