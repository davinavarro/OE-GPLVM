{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baca321-dce7-4907-b555-420f41bd25b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f9024-fe7a-4a2a-842f-935b6a6b7822",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from new_aeb_gplvm import *\n",
    "from utils.data_generator import DataGenerator\n",
    "from utils.myutils import Utils\n",
    "from tqdm import trange\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm_notebook\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "utils = Utils()\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f6842a-7788-45cd-8a6e-0b84ef7cd505",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataframe(experiment):\n",
    "    datagenerator = DataGenerator()\n",
    "\n",
    "    noise_type = (\n",
    "        None if experiment[\"noise_type\"] == \"normal\" else experiment[\"noise_type\"]\n",
    "    )  # irrelevant,duplicated\n",
    "    anomaly_type = (\n",
    "        None if experiment[\"anomaly_type\"] == \"normal\" else experiment[\"anomaly_type\"]\n",
    "    )  # cluster,global,local,dependency\n",
    "\n",
    "    datagenerator.dataset = experiment[\"dataset\"]\n",
    "    data = datagenerator.generator(\n",
    "        la=1.00,\n",
    "        realistic_synthetic_mode=anomaly_type,\n",
    "        noise_type=noise_type,\n",
    "        noise_ratio=float(experiment[\"noise_ratio\"]),\n",
    "        stdscale=True,\n",
    "        minmax=False,\n",
    "    )\n",
    "\n",
    "    Y_train = torch.tensor(data[\"X_train\"], dtype=torch.float32)\n",
    "    Y_test = torch.tensor(data[\"X_test\"], dtype=torch.float32)\n",
    "    lb_train = torch.tensor(data[\"y_train\"], dtype=torch.float32)\n",
    "    lb_test = torch.tensor(data[\"y_test\"], dtype=torch.float32)\n",
    "\n",
    "    return Y_train, Y_test, lb_train, lb_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee20fcbe-1816-4ddd-8db1-287ac5313431",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXPERIMENTS_FILE = \"experiments/complete/000_datasets_01_47_normal_03_best.json\"\n",
    "with open(EXPERIMENTS_FILE) as file:\n",
    "    experiments = json.load(file)\n",
    "df = pd.DataFrame(experiments)\n",
    "df = df[df.dataset != \"34_smtp\"]\n",
    "experiments = df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aaff3b-7296-4439-8427-f1273d314c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[[\"dataset\", \"val_auc_roc\"]].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fb576e-7dd3-4065-8e0b-a14d570d6414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "success_experiments = []\n",
    "failed_experiments = []\n",
    "for experiment in tqdm_notebook(experiments[0:1]):\n",
    "    Y_train, Y_test, lb_train, lb_test = create_dataframe(experiment)\n",
    "    Y_val, Y_test, lb_val, lb_test = train_test_split(\n",
    "        Y_test, lb_test, test_size=0.50, random_state=42\n",
    "    )\n",
    "\n",
    "    n_train = len(Y_train)\n",
    "    data_dim = Y_train.shape[1]\n",
    "    kernel = experiment[\"kernel\"]\n",
    "    latent_dim = int(experiment[\"latent_dim\"])\n",
    "    nn_layers = tuple(map(int, experiment[\"layers\"].split(\",\")))\n",
    "    n_inducing = int(experiment[\"n_inducing\"])\n",
    "    n_epochs = int(experiment[\"n_epochs\"])\n",
    "    lr = float(experiment[\"learning_rate\"])\n",
    "    batch_size = int(experiment[\"batch_size\"])\n",
    "    dataset = experiment[\"dataset\"]\n",
    "\n",
    "    # print(experiment)\n",
    "\n",
    "    try:\n",
    "        gplvm = AD_GPLVM(\n",
    "            latent_dim, n_inducing, n_epochs, nn_layers, lr, batch_size, kernel\n",
    "        )\n",
    "\n",
    "        # Fitting the Model\n",
    "        train_start_time = time.time()\n",
    "        gplvm.fit(Y_train)\n",
    "        train_end_time = time.time()\n",
    "\n",
    "        # Validating the Model\n",
    "        val = []\n",
    "        for i in range(100):\n",
    "            score = gplvm.predict_score(Y_val)\n",
    "            val.append(score)\n",
    "        validation_score = np.mean(val, axis=0)\n",
    "        # validation_score = gplvm.calculate_train_elbo(Y_train_normal)\n",
    "\n",
    "        # Results\n",
    "        pred_start_time = time.time()\n",
    "        test_score = gplvm.predict_score(Y_test)\n",
    "        pred_end_time = time.time()\n",
    "\n",
    "        # Save Metrics\n",
    "        metrics = utils.metric(y_true=lb_val, y_score=validation_score)\n",
    "        validation_metrics = utils.metric(y_true=lb_test, y_score=test_score)\n",
    "        experiment[\"negative_elbo\"] = validation_score.sum()  # validation_score.sum()\n",
    "        experiment[\"train_loss_curve\"] = gplvm.loss_list\n",
    "        experiment[\"val_auc_roc\"] = validation_metrics[\"aucroc\"]\n",
    "        experiment[\"val_auc_pr\"] = validation_metrics[\"aucpr\"]\n",
    "        experiment[\"test_auc_roc\"] = metrics[\"aucroc\"]\n",
    "        experiment[\"test_auc_pr\"] = metrics[\"aucpr\"]\n",
    "        experiment[\"training_time\"] = train_end_time - train_start_time\n",
    "        experiment[\"inference_time\"] = pred_end_time - pred_start_time\n",
    "\n",
    "        # Reconstrucao\n",
    "        Y_val_recon, Y_val_recon_covar = gplvm.model.reconstruct_y(Y_val)\n",
    "        experiment[\"val_reconstruct_error\"] = float(utils.rmse(Y_val, Y_val_recon.T))\n",
    "\n",
    "        pd.Series(experiment).to_json(\n",
    "            f\"experiments/complete/results/contaminated/{dataset}.json\"\n",
    "        )\n",
    "\n",
    "        # utils.save_experiment(experiment)\n",
    "\n",
    "    except Exception as error:\n",
    "        print(\"An exception occurred:\", error)\n",
    "        experiment[\"test_auc_roc\"] = 0.0\n",
    "        experiment[\"test_auc_pr\"] = 0.0\n",
    "        pd.Series(experiment).to_json(\n",
    "            f\"experiments/complete/results/contaminated/{dataset}.json\"\n",
    "        )\n",
    "        # utils.save_experiment(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9559f8-97cc-4af6-ac57-f7df2a2b758f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_contamined = utils.read_json_from_folder(\n",
    "    \"experiments/complete/results/contaminated/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468ddbd7-1253-499b-b6e8-ede07da140f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_contamined.to_json(\"000_datasets_01_47_contamined_01_results.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50410a2f-b650-42b9-a21c-aef8813f76d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(df[\"test_auc_roc\"] - df_contamined[\"test_auc_roc\"]).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac446bb-d53d-4d54-8741-8c0bab757113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.boxplot([df[\"test_auc_roc\"], df_contamined[\"test_auc_roc\"]])\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9518332d-6da2-4f7b-86c8-5e1c7b9bf031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_contamined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2541ace-828f-4e38-8152-2155f8ae17ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
