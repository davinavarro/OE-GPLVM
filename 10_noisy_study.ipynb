{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4110f34-3e7e-4b49-a60f-5f958dce88e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 03:51:48.082350: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-29 03:51:48.121101: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from new_aeb_gplvm import *\n",
    "from utils.data_generator import DataGenerator\n",
    "from utils.myutils import Utils\n",
    "from tqdm import trange\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "random.seed(42)\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "datagenerator = DataGenerator()\n",
    "utils = Utils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "779feb05-4a15-4aaf-827a-b83537ffc774",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXPERIMENTS_FILE = \"experiments/noisy/004_irrelevant_anomaly_all_experiments.json\"\n",
    "with open(EXPERIMENTS_FILE) as file:\n",
    "    experiments = json.load(file)\n",
    "OUTPUT_FILE = EXPERIMENTS_FILE.replace(\"experiments.json\", \"results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "345172d5-0c40-4d79-831e-50cab08c0cf3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#EXPERIMENTS_FILE = \"experiments/normal/005_init_lat_ind_best.json\"\n",
    "#with open(EXPERIMENTS_FILE) as file:\n",
    "#    experiments = json.load(file)\n",
    "#NOISE_RATIO = 0.50\n",
    "#for experiment in experiments:\n",
    "#    del experiment['auc_roc']\n",
    "#    del experiment['auc_pr']\n",
    "#    experiment['noise_type'] = \"irrelevant_features\"\n",
    "#    experiment['noise_ratio'] =  NOISE_RATIO\n",
    "#with open( f\"experiments/noisy/003_irrelevant_features_{int(100*NOISE_RATIO)}.json\", \"w\") as file:\n",
    "#    json.dump(experiments, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed06f968-4325-4faf-98d4-8c2a0b542907",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# anomaly_type = \"dependency\"\n",
    "# for experiment in experiments:\n",
    "#    experiment[\"anomaly_type\"] = anomaly_type\n",
    "# with open(f\"experiments/noisy/002_anomaly_study_{anomaly_type}.json\", \"w\") as file:\n",
    "#    json.dump(experiments,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c8a143e-4886-49a6-b9a6-085cd608c286",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#experiments = []\n",
    "#path = \"experiments/noisy/\"\n",
    "#for file in os.listdir(path):\n",
    "#    if file.find(\"_irrelevant_features_\") > -1:\n",
    "#        print(path+file)\n",
    "#        with open(path+file, \"r\") as file:\n",
    "#            experiments += json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11da3617-2fa2-4ba4-8426-5a7e0033fa1a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for experiment in experiments:\n",
    "#    del experiment['auc_pr']\n",
    "#    del experiment['auc_roc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37f0b8d1-bd1b-486c-80d0-a69f76061051",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#with open(f\"experiments/noisy/003_irrelevant_features_all_experiments.json\", \"w\") as file:\n",
    "#    json.dump(experiments,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcae9b61-f906-4446-ae37-95d01ffcc78d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#with open(f\"experiments/noisy/003_irrelevant_features_all_experiments.json\") as irr_file:\n",
    "#    experiment_irr = json.load(irr_file)\n",
    "#with open(f\"experiments/noisy/002_anomaly_study_all_experiments.json\") as ano_file:\n",
    "#    experiment_ano = json.load(ano_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b089eb6-6dad-4582-8a6a-02b8da2d7225",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#experiments = experiment_irr +  experiment_ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec8df45e-348a-4442-9633-922c3a826780",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#with open(f\"experiments/noisy/004_irrelevant_anomaly_all_experiments.json\", \"w\") as file:\n",
    "#    json.dump(experiments,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea1218ac-4739-48c2-b2e0-08a41e5e09ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_anomaly_dataframe(dataset, anomaly_type=None, noise_type=None, noise_ratio=None):\n",
    "    datagenerator.dataset = dataset\n",
    "    data = datagenerator.generator(\n",
    "        la=1.00,\n",
    "        realistic_synthetic_mode=anomaly_type,\n",
    "        stdscale=True,\n",
    "        minmax=False,\n",
    "        noise_type=noise_type,\n",
    "        noise_ratio=noise_ratio\n",
    "    )\n",
    "    Y_train = torch.tensor(data[\"X_train\"], dtype=torch.float32)\n",
    "    Y_test = torch.tensor(data[\"X_test\"], dtype=torch.float32)\n",
    "    lb_train = torch.tensor(data[\"y_train\"], dtype=torch.float32)\n",
    "    lb_test = torch.tensor(data[\"y_test\"], dtype=torch.float32)\n",
    "\n",
    "    return Y_train, Y_test, lb_train, lb_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f81bd92-0989-42e1-8c95-cc98fab7a5cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28422/2407570982.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for experiment in tqdm_notebook(experiments):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24844655fb484819b0d3150e53004c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/423 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Experimento: {'dataset': '01_ALOI', 'kernel': 'rbf', 'layers': '5,5', 'latent_dim': 13, 'lr': 0.01, 'batch_size': 128, 'n_inducing': 50, 'n_epochs': 1000, 'noise_type': 'irrelevant_features', 'noise_ratio': 0.01}\n",
      "subsampling for dataset 01_ALOI...\n",
      "current noise type: irrelevant_features\n",
      "{'Samples': 10000, 'Features': 27, 'Anomalies': 302, 'Anomalies Ratio(%)': 3.02}\n",
      "Kernel não escolhido!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                               | 0/1000 [00:00<?, ?it/s]\u001b[A\n",
      "                                                                                                                                                                                             \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Experimento: {'dataset': '02_annthyroid', 'kernel': 'rbf', 'layers': '10,10,10', 'latent_dim': 3, 'lr': 0.01, 'batch_size': 128, 'n_inducing': 50, 'n_epochs': 1000, 'noise_type': 'irrelevant_features', 'noise_ratio': 0.01}\n",
      "current noise type: irrelevant_features\n",
      "{'Samples': 7200, 'Features': 6, 'Anomalies': 534, 'Anomalies Ratio(%)': 7.42}\n",
      "Kernel não escolhido!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                               | 0/1000 [00:00<?, ?it/s]\u001b[A\n",
      "Loss: 15.91, iter no: 0:   0%|                                                                                                                                      | 0/1000 [00:00<?, ?it/s]\u001b[A\n",
      "Loss: 15.91, iter no: 0:  10%|████████████▍                                                                                                               | 100/1000 [00:01<00:16, 55.00it/s]\u001b[A\n",
      "Loss: 15.91, iter no: 0:  20%|████████████████████████▊                                                                                                   | 200/1000 [00:03<00:14, 56.22it/s]\u001b[A\n",
      "Loss: 15.91, iter no: 0:  30%|█████████████████████████████████████▏                                                                                      | 300/1000 [00:05<00:11, 58.54it/s]\u001b[A\n",
      "Loss: 15.91, iter no: 0:  40%|█████████████████████████████████████████████████▌                                                                          | 400/1000 [00:07<00:10, 57.23it/s]\u001b[A\n",
      "Loss: 15.91, iter no: 0:  50%|██████████████████████████████████████████████████████████████                                                              | 500/1000 [00:08<00:08, 57.68it/s]\u001b[A\n",
      "Loss: 8.54, iter no: 500:  50%|█████████████████████████████████████████████████████████████▌                                                             | 500/1000 [00:08<00:08, 57.68it/s]\u001b[A\n",
      "Loss: 8.54, iter no: 500:  60%|█████████████████████████████████████████████████████████████████████████▊                                                 | 600/1000 [00:10<00:06, 57.63it/s]\u001b[A\n",
      "Loss: 8.54, iter no: 500:  70%|██████████████████████████████████████████████████████████████████████████████████████                                     | 700/1000 [00:12<00:05, 53.53it/s]\u001b[A\n",
      "Loss: 8.54, iter no: 500:  80%|██████████████████████████████████████████████████████████████████████████████████████████████████▍                        | 800/1000 [00:14<00:03, 55.35it/s]\u001b[A\n",
      "Loss: 8.54, iter no: 500:  90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▋            | 900/1000 [00:15<00:01, 56.51it/s]\u001b[A\n",
      "Loss: 8.54, iter no: 500: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:17<00:00, 57.70it/s]\u001b[A\n",
      "                                                                                                                                                                                             \u001b[A/home/jovyan/work/new_aeb_gplvm.py:302: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3277.)\n",
      "  klu_expanded = ll_shape.T.add_(klu).sum(-1).T.div((self.n_train))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Experimento: {'dataset': '03_backdoor', 'kernel': 'rbf', 'layers': '15,15', 'latent_dim': 2, 'lr': 0.01, 'batch_size': 128, 'n_inducing': 50, 'n_epochs': 1000, 'noise_type': 'irrelevant_features', 'noise_ratio': 0.01}\n",
      "subsampling for dataset 03_backdoor...\n",
      "current noise type: irrelevant_features\n",
      "{'Samples': 10000, 'Features': 197, 'Anomalies': 236, 'Anomalies Ratio(%)': 2.36}\n",
      "Kernel não escolhido!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                               | 0/1000 [00:00<?, ?it/s]\u001b[A\n",
      "Loss: 304.62, iter no: 0:   0%|                                                                                                                                     | 0/1000 [00:00<?, ?it/s]\u001b[A\n",
      "Loss: 304.62, iter no: 0:  10%|████████████▎                                                                                                              | 100/1000 [00:03<00:30, 29.19it/s]\u001b[A\n",
      "Loss: 304.62, iter no: 0:  20%|████████████████████████▌                                                                                                  | 200/1000 [00:06<00:26, 29.87it/s]\u001b[A\n",
      "Loss: 304.62, iter no: 0:  30%|████████████████████████████████████▉                                                                                      | 300/1000 [00:10<00:23, 29.31it/s]\u001b[A\n",
      "Loss: 304.62, iter no: 0:  40%|█████████████████████████████████████████████████▏                                                                         | 400/1000 [00:14<00:21, 27.71it/s]\u001b[A\n",
      "Loss: 304.62, iter no: 0:  50%|█████████████████████████████████████████████████████████████▌                                                             | 500/1000 [00:17<00:17, 27.97it/s]\u001b[A\n",
      "Loss: 200.66, iter no: 500:  50%|████████████████████████████████████████████████████████████▌                                                            | 500/1000 [00:17<00:17, 27.97it/s]\u001b[A\n",
      "Loss: 200.66, iter no: 500:  60%|████████████████████████████████████████████████████████████████████████▌                                                | 600/1000 [00:21<00:14, 28.33it/s]\u001b[A\n",
      "Loss: 200.66, iter no: 500:  70%|████████████████████████████████████████████████████████████████████████████████████▋                                    | 700/1000 [00:24<00:10, 28.32it/s]\u001b[A\n",
      "Loss: 200.66, iter no: 500:  80%|████████████████████████████████████████████████████████████████████████████████████████████████▊                        | 800/1000 [00:28<00:07, 28.33it/s]\u001b[A\n",
      "Loss: 200.66, iter no: 500:  90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▉            | 900/1000 [00:31<00:03, 28.69it/s]\u001b[A\n",
      "Loss: 200.66, iter no: 500: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:35<00:00, 27.73it/s]\u001b[A\n",
      "                                                                                                                                                                                             \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Experimento: {'dataset': '04_breastw', 'kernel': 'rbf', 'layers': '10,10,10', 'latent_dim': 4, 'lr': 0.01, 'batch_size': 128, 'n_inducing': 50, 'n_epochs': 1000, 'noise_type': 'irrelevant_features', 'noise_ratio': 0.01}\n",
      "generating duplicate samples for dataset 04_breastw...\n",
      "current noise type: irrelevant_features\n",
      "{'Samples': 1000, 'Features': 9, 'Anomalies': 360, 'Anomalies Ratio(%)': 36.0}\n",
      "Kernel não escolhido!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                               | 0/1000 [00:00<?, ?it/s]\u001b[A\n",
      "Loss: 30.66, iter no: 0:   0%|                                                                                                                                      | 0/1000 [00:00<?, ?it/s]\u001b[A\n",
      "Loss: 30.66, iter no: 0:  10%|████████████▎                                                                                                              | 100/1000 [00:00<00:07, 112.80it/s]\u001b[A\n",
      "Loss: 30.66, iter no: 0:  20%|████████████████████████▌                                                                                                  | 200/1000 [00:01<00:07, 113.91it/s]\u001b[A\n",
      "Loss: 30.66, iter no: 0:  30%|████████████████████████████████████▉                                                                                      | 300/1000 [00:02<00:06, 110.81it/s]\u001b[A\n",
      "Loss: 30.66, iter no: 0:  40%|█████████████████████████████████████████████████▏                                                                         | 400/1000 [00:03<00:05, 113.45it/s]\u001b[A\n",
      "Loss: 30.66, iter no: 0:  50%|█████████████████████████████████████████████████████████████▌                                                             | 500/1000 [00:04<00:04, 116.82it/s]\u001b[A\n",
      "Loss: 9.27, iter no: 500:  50%|█████████████████████████████████████████████████████████████                                                             | 500/1000 [00:04<00:04, 116.82it/s]\u001b[A\n",
      "Loss: 9.27, iter no: 500:  60%|█████████████████████████████████████████████████████████████████████████▏                                                | 600/1000 [00:05<00:03, 118.47it/s]\u001b[A\n",
      "Loss: 9.27, iter no: 500:  70%|█████████████████████████████████████████████████████████████████████████████████████▍                                    | 700/1000 [00:06<00:02, 116.81it/s]\u001b[A\n",
      "Loss: 9.27, iter no: 500:  80%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                        | 800/1000 [00:06<00:01, 114.32it/s]\u001b[A\n",
      "Loss: 9.27, iter no: 500:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▊            | 900/1000 [00:07<00:00, 110.09it/s]\u001b[A\n",
      "Loss: 9.27, iter no: 500: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:08<00:00, 112.40it/s]\u001b[A\n",
      "                                                                                                                                                                                             \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Experimento: {'dataset': '05_campaign', 'kernel': 'rbf', 'layers': '5,5', 'latent_dim': 15, 'lr': 0.01, 'batch_size': 128, 'n_inducing': 100, 'n_epochs': 1000, 'noise_type': 'irrelevant_features', 'noise_ratio': 0.01}\n",
      "subsampling for dataset 05_campaign...\n",
      "current noise type: irrelevant_features\n",
      "{'Samples': 10000, 'Features': 62, 'Anomalies': 1103, 'Anomalies Ratio(%)': 11.03}\n",
      "Kernel não escolhido!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                               | 0/1000 [00:00<?, ?it/s]\u001b[A\n",
      "Loss: 181.49, iter no: 0:   0%|                                                                                                                                     | 0/1000 [00:00<?, ?it/s]\u001b[A\n",
      "Loss: 181.49, iter no: 0:  10%|████████████▎                                                                                                              | 100/1000 [00:09<01:29, 10.04it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "for experiment in tqdm_notebook(experiments):\n",
    "    print(f\"Start Experimento: {experiment}\")\n",
    "    if \"auc_roc\" not in experiment.keys() and \"anomaly_type\" in experiment.keys():\n",
    "        Y_train, Y_test, lb_train, lb_test = create_anomaly_dataframe(\n",
    "            experiment[\"dataset\"], \n",
    "            realistic_synthetic_mode=experiment[\"anomaly_type\"]\n",
    "        )\n",
    "    if \"auc_roc\" not in experiment.keys() and \"noise_type\" in experiment.keys():\n",
    "        Y_train, Y_test, lb_train, lb_test = create_anomaly_dataframe(\n",
    "            experiment[\"dataset\"],\n",
    "            noise_type=experiment[\"noise_type\"],\n",
    "            noise_ratio=experiment[\"noise_ratio\"],\n",
    "        )\n",
    "\n",
    "        n_train = len(Y_train)\n",
    "        data_dim = Y_train.shape[1]\n",
    "        latent_dim = experiment[\"latent_dim\"]\n",
    "        nn_layers = tuple(map(int, experiment[\"layers\"].split(\",\")))\n",
    "        kernel = experiment[\"kernel\"]\n",
    "        n_inducing = experiment[\"n_inducing\"]\n",
    "\n",
    "        n_epochs = 1000\n",
    "        lr = 0.01\n",
    "        batch_size = 128\n",
    "\n",
    "        try:\n",
    "            gplvm = AD_GPLVM(\n",
    "                latent_dim, n_inducing, n_epochs, nn_layers, lr, batch_size\n",
    "            )\n",
    "            gplvm.fit(Y_train)\n",
    "            score = gplvm.predict_score(Y_test)\n",
    "            metrics = utils.metric(y_true=lb_test, y_score=score)\n",
    "\n",
    "            experiment[\"auc_roc\"] = metrics[\"aucroc\"]\n",
    "            experiment[\"auc_pr\"] = metrics[\"aucpr\"]\n",
    "        except:\n",
    "            experiment[\"auc_roc\"] = 0.00\n",
    "            experiment[\"auc_pr\"] = 0.00\n",
    "\n",
    "        experiment[\"lr\"] = lr\n",
    "        experiment[\"batch_size\"] = batch_size\n",
    "        experiment[\"n_epochs\"] = n_epochs\n",
    "\n",
    "        experiment[\"train_noise\"] = float(lb_train.sum() / len(Y_train))\n",
    "\n",
    "        with open(OUTPUT_FILE, \"w\") as file:\n",
    "            json.dump(experiments, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3d9c3d6-8334-4bda-b971-84330a5e1f11",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(experiments)\u001b[38;5;241m.\u001b[39mto_csv(OUTPUT_FILE\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(experiments).to_csv(OUTPUT_FILE.replace(\".json\", \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60485140-6e81-4b69-9af3-57e9d1704b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
